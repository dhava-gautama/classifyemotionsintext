# -*- coding: utf-8 -*-
"""Classify Emotions in text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11n52Ip2sCQM90vq3e30qqlbV_rRGx_nC

**Dhava Gautama**
<br>Klasifikasi emosi dalam tulisan. Data yang digunakan adalah data **Emotions dataset for NLP** yang bersumber dari **Kaggle** (https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp?datasetId=605165)
"""

# Import Library
import pandas as pd
import re

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

import matplotlib.pyplot as plt

# Load Data
df = pd.read_csv("/content/emosi.csv")
df.head()

# Check Jumlah Emosi
df['emotion'].value_counts()

# Mengecek nilai kosong
df.isnull().values.any()

# Labeling Emosi
emotion = pd.get_dummies(df.emotion)
df_emotion = pd.concat([df, emotion], axis=1)
df_emotion = df_emotion.drop(columns='emotion')
df_emotion.head()

# Mengubah tipe data menjadi str dan numpy array 
text = df_emotion['text'].astype(str)
label = df_emotion[['anger', 'fear','joy','love','sadness','surprise']].values

# Split dataset (20% dari dataset sebagai validation)
emotion_train, emotion_test, label_train, label_test = train_test_split(text, label, test_size = 0.2)
print('Jumlah sample training:',len(emotion_train))
print('Jumlah sample test:',len(emotion_test))

# Tokenizer
tokenizer = Tokenizer(num_words=15212, oov_token='x')
tokenizer.fit_on_texts(emotion_train) 
tokenizer.fit_on_texts(emotion_test)
 
sequence_train = tokenizer.texts_to_sequences(emotion_train)
sequence_test = tokenizer.texts_to_sequences(emotion_test)
 
padded_train = pad_sequences(sequence_train) 
padded_test = pad_sequences(sequence_test)

# Gunakan model LSTM dengan Embedding
model = Sequential([
    Embedding(input_dim=15212, output_dim=64),
    LSTM(64),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(6, activation='softmax')
])
print(model.summary())

# Model di compile dengan menggunakan optimizer Adam
model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])

# Callbacks
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("\nAkurasi train dan validasi didapat telah mencapai nilai > 90%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 20
history = model.fit(padded_train, label_train, epochs=num_epochs, validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

# Plot Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()